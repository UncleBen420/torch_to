{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0e29f7c-d6a9-43bf-b285-85cd1569dca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rvx/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "import torch \n",
    "import numpy as np\n",
    "\n",
    "mean=[0.49139968, 0.48215827 ,0.44653124]\n",
    "std=[0.24703233, 0.24348505, 0.26158768]\n",
    "transform = transforms.Compose([\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize(mean=mean,std=std)]\n",
    "                              )\n",
    "ds = CIFAR10(root='/tmp', download=True, transform=transform)\n",
    "\n",
    "dl = DataLoader(ds,\n",
    "                batch_size=100,\n",
    "                pin_memory=True,\n",
    "                num_workers=2,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26f01931-153c-4e6b-9948-ea03ba463ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rvx/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/rvx/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "cal_ds = []\n",
    "cal_lbl = []\n",
    "\n",
    "calibration_length = 100\n",
    "for batch in dl:\n",
    "    if len(cal_lbl) > calibration_length:\n",
    "        break\n",
    "    images, labels = batch\n",
    "    cal_ds.extend(images.cpu().numpy().tolist())\n",
    "    cal_lbl.extend(labels.cpu().numpy().tolist())\n",
    "\n",
    "calibration_samples = np.array(cal_ds, dtype=np.float32)[:calibration_length]\n",
    "calibration_labels = np.expand_dims(np.array(cal_lbl)[:calibration_length], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd1b555c-54c8-4667-85d7-bb7eebaafd9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-15 12:04:16.277338: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/Users/rvx/Library/Python/3.9/lib/python/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from torchto.converter import Converter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9578609-3f2a-4391-9ef0-7c58f838bd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUB\n",
    "#calibration_samples = np.load('../../cub_samples_cab.npy')\n",
    "#calibration_labels = np.load('../../cub_labels_cab.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c11c74e-f688-4475-9ada-b683d8fcb42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = torch.load('../../zico_bc.pth', map_location='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "491c3cdc-d398-4ab7-a7ce-51ed89a17860",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/rvx/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "ONNX\n",
      "================ Diagnostic Run torch.onnx.export version 2.0.1 ================\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load(\"chenyaofo/pytorch-cifar-models\", \"cifar10_resnet20\", pretrained=True)\n",
    "dummy_input = torch.rand(1,3,32,32)\n",
    "\n",
    "for conv_type in ['ONNX']:\n",
    "    print('-'*30)\n",
    "    print(conv_type)\n",
    "    converter = Converter(conv_type,\n",
    "                          calibration_samples=calibration_samples,\n",
    "                          calibration_labels=calibration_labels,\n",
    "                          dummy_input=dummy_input, \n",
    "                          verbose=False)\n",
    "    converted_model = converter(model, dir='dummy', name='dummy')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ac2c765-33ff-473d-9fa3-f28d77fd894e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "TFLITE\n",
      "INFO:tensorflow:Assets written to: dummy/dummy/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: dummy/dummy/assets\n",
      "2024-01-15 12:05:16.319022: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-01-15 12:05:16.319051: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-01-15 12:05:16.320763: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: dummy/dummy\n",
      "2024-01-15 12:05:16.323561: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-01-15 12:05:16.323576: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: dummy/dummy\n",
      "2024-01-15 12:05:16.328872: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:382] MLIR V1 optimization pass is not enabled\n",
      "2024-01-15 12:05:16.330066: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-01-15 12:05:16.386791: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: dummy/dummy\n",
      "2024-01-15 12:05:16.408683: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 87926 microseconds.\n",
      "2024-01-15 12:05:16.458643: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-01-15 12:05:16.597541: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:2245] Estimated count of arithmetic ops: 81.913 M  ops, equivalently 40.957 M  MACs\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "dummy_input = torch.rand(1,3,32,32)\n",
    "model = onnx.load('dummy/dummy.onnx')\n",
    "for conv_type in ['TFLITE']:\n",
    "    print('-'*30)\n",
    "    print(conv_type)\n",
    "    converter = Converter(conv_type,\n",
    "                          calibration_samples=calibration_samples,\n",
    "                          calibration_labels=calibration_labels,\n",
    "                          dummy_input=dummy_input, \n",
    "                          verbose=False)\n",
    "    converted_model = converter(model, dir='dummy', name='dummy')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
